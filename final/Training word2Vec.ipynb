{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/danieljunior/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from gensim import utils\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "csv.field_size_limit(100000000)\n",
    "\n",
    "class TCUCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        #source: https://medium.com/ml2vec/using-word2vec-to-analyze-reddit-comments-28945d8cee57\n",
    "        \n",
    "        #Normalize tabs and remove newlines\n",
    "        no_tabs = str(text).replace('\\t', ' ').replace('\\n', '');\n",
    "        \n",
    "        #Remove all characters except A-Z\n",
    "        alphas_only = re.sub(\"[^a-zA-Z]\", \" \", no_tabs);\n",
    "        \n",
    "        #Normalize spaces to 1\n",
    "        multi_spaces = re.sub(\" +\", \" \", alphas_only);\n",
    "        \n",
    "        #Strip trailing and leading spaces\n",
    "        no_spaces = multi_spaces.strip();\n",
    "        \n",
    "        #Remove stopwords \n",
    "        stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "        clean_text = [w for w in no_spaces.split() if not w in stopwords] \n",
    "\n",
    "        return ' '.join(clean_text)\n",
    "                \n",
    "\n",
    "    def __iter__(self):\n",
    "        filename = 'datasets/acordaos_relator_5k.csv'\n",
    "        with open(filename, \"r\") as csvfile:\n",
    "            corpus = csv.reader(csvfile)\n",
    "            next(corpus) #ignores header\n",
    "            for doc in corpus:\n",
    "                yield  utils.simple_preprocess(self.clean_text(doc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = TCUCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences, min_count=50, size=300, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.bin')\n",
    "# loaded_model = gensim.models.Word2Vec.load('model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/danieljunior/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# source: https://github.com/v1shwa/document-similarity/blob/master/DocSim.py\n",
    "import numpy as np\n",
    "from gensim import utils\n",
    "import re\n",
    "import nltk \n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class DocSim:\n",
    "    \n",
    "    def __init__(self, w2v_model):\n",
    "        self.w2v_model = w2v_model\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        #source: https://medium.com/ml2vec/using-word2vec-to-analyze-reddit-comments-28945d8cee57\n",
    "        \n",
    "        #Normalize tabs and remove newlines\n",
    "        no_tabs = str(text).replace('\\t', ' ').replace('\\n', '');\n",
    "        \n",
    "        #Remove all characters except A-Z\n",
    "        alphas_only = re.sub(\"[^a-zA-Z]\", \" \", no_tabs);\n",
    "        \n",
    "        #Normalize spaces to 1\n",
    "        multi_spaces = re.sub(\" +\", \" \", alphas_only);\n",
    "        \n",
    "        #Strip trailing and leading spaces\n",
    "        no_spaces = multi_spaces.strip();\n",
    "        \n",
    "        #Remove stopwords\n",
    "        stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "        clean_text = [w for w in no_spaces.split() if not w in stopwords] \n",
    "\n",
    "        return ' '.join(clean_text)\n",
    "\n",
    "\n",
    "    def vectorize(self, doc: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Identify the vector values for each word in the given document\n",
    "        :param doc:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "#         words = utils.simple_preprocess(self.clean_text(doc))\n",
    "        word_vecs = []\n",
    "        for word in doc:\n",
    "            try:\n",
    "                vec = self.w2v_model.wv[word]\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "                # Ignore, if the word doesn't exist in the vocabulary\n",
    "                pass\n",
    "\n",
    "        # Assuming that document vector is the mean of all the word vectors\n",
    "        # PS: There are other & better ways to do it.\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "\n",
    "    def calculate_similarity(self, source_doc, target_docs=None, threshold=0):\n",
    "        \"\"\"Calculates & returns similarity scores between given source document & all\n",
    "        the target documents.\"\"\"\n",
    "        if not target_docs:\n",
    "            return []\n",
    "\n",
    "        if isinstance(target_docs, str):\n",
    "            target_docs = [target_docs]\n",
    "\n",
    "        source_vec = self.vectorize(source_doc)\n",
    "        results = []\n",
    "        for doc in target_docs:\n",
    "            target_vec = self.vectorize(doc)\n",
    "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
    "            if sim_score > threshold:\n",
    "                results.append({\"score\": sim_score, \"doc\": doc})\n",
    "            # Sort results by score in desc order\n",
    "            results.sort(key=lambda k: k[\"score\"], reverse=True)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "class TCUAnnoyIndexer:\n",
    "    \n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.indexer = None\n",
    "\n",
    "    def build(self, corpus, n_tree=10, metric='angular'):\n",
    "        f = self.word2vec.vector_size\n",
    "        t = AnnoyIndex(f, metric)  # Length of item vector that will be indexed\n",
    "        for i, doc in enumerate(corpus):\n",
    "            v = DocSim(self.word2vec).vectorize(doc)\n",
    "            t.add_item(i, v)\n",
    "\n",
    "        t.build(n_tree)\n",
    "        self.indexer = t\n",
    "    \n",
    "    def save(self, path='test.ann'):\n",
    "        self.indexer.save(path)\n",
    "    \n",
    "    def load(self, path='test.ann', metric='angular'):\n",
    "        self.indexer = AnnoyIndex(self.word2vec.vector_size, metric)\n",
    "        self.indexer.load(path) # super fast, will just mmap the file\n",
    "\n",
    "    def get_k_neighbors(self, item_id, k):\n",
    "        return self.indexer.get_nns_by_item(item_id, k) # will find the 1000 nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = TCUCorpus()\n",
    "indexer = TCUAnnoyIndexer(model)\n",
    "indexer.build(docs, n_tree=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = TCUAnnoyIndexer(model)\n",
    "indexer.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 301, 623, 227140, 414]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.get_k_neighbors(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.41857677698135376,\n",
       " 0.594915509223938,\n",
       " 0.5671983957290649,\n",
       " -0.8950641751289368,\n",
       " -0.16800275444984436,\n",
       " -0.006473747082054615,\n",
       " -0.18669268488883972,\n",
       " 0.32550209760665894,\n",
       " -0.10208466649055481,\n",
       " -0.1160338893532753,\n",
       " 0.7734190821647644,\n",
       " -0.10675669461488724,\n",
       " -0.43691563606262207,\n",
       " 0.21447418630123138,\n",
       " -0.7320036888122559,\n",
       " 0.23761135339736938,\n",
       " -0.055727001279592514,\n",
       " 0.6368032693862915,\n",
       " -0.15061238408088684,\n",
       " -0.07796695083379745,\n",
       " 0.22029219567775726,\n",
       " 0.5957158207893372,\n",
       " -0.2652522325515747,\n",
       " 0.07908584177494049,\n",
       " 0.29124340415000916,\n",
       " 0.02937070094048977,\n",
       " 0.3197613060474396,\n",
       " -0.7666438817977905,\n",
       " 0.13228237628936768,\n",
       " 0.19182248413562775,\n",
       " -0.05887952819466591,\n",
       " 0.29060548543930054,\n",
       " 0.43367335200309753,\n",
       " -0.08448410779237747,\n",
       " -0.18387064337730408,\n",
       " -0.120962955057621,\n",
       " 0.018008029088377953,\n",
       " 0.16499193012714386,\n",
       " -0.2880810797214508,\n",
       " 0.21324284374713898,\n",
       " -0.09496060758829117,\n",
       " -0.10431899130344391,\n",
       " 0.8365148901939392,\n",
       " -0.3765210509300232,\n",
       " -0.11423588544130325,\n",
       " -0.16725988686084747,\n",
       " -0.12723088264465332,\n",
       " -0.22606128454208374,\n",
       " 0.2200574278831482,\n",
       " 0.08654365688562393,\n",
       " -0.26037681102752686,\n",
       " 0.28500211238861084,\n",
       " 0.2427835613489151,\n",
       " -0.5274671316146851,\n",
       " -0.04041716828942299,\n",
       " 0.5592809915542603,\n",
       " -0.34934911131858826,\n",
       " 0.11465705931186676,\n",
       " 0.023831898346543312,\n",
       " -0.1702539622783661,\n",
       " 0.07894078642129898,\n",
       " 0.22160252928733826,\n",
       " -0.06392735242843628,\n",
       " -0.9639818668365479,\n",
       " 0.1756073385477066,\n",
       " -0.23351514339447021,\n",
       " -0.12852363288402557,\n",
       " 0.2778407633304596,\n",
       " -0.19689080119132996,\n",
       " 0.5180817246437073,\n",
       " -0.16515827178955078,\n",
       " -0.2774370610713959,\n",
       " 0.11696258932352066,\n",
       " -0.1133633553981781,\n",
       " 0.5264339447021484,\n",
       " 0.03003215789794922,\n",
       " 0.004448074847459793,\n",
       " 0.022203881293535233,\n",
       " -0.1819283664226532,\n",
       " -0.5721429586410522,\n",
       " 0.011368838138878345,\n",
       " 0.0885830819606781,\n",
       " -0.25484499335289,\n",
       " 0.11751037836074829,\n",
       " 0.11812297999858856,\n",
       " 0.4632675349712372,\n",
       " 0.2712723910808563,\n",
       " 0.33446964621543884,\n",
       " 0.1240004301071167,\n",
       " 0.027894720435142517,\n",
       " 0.18056130409240723,\n",
       " 0.7776762247085571,\n",
       " -0.5350757241249084,\n",
       " 0.8563913106918335,\n",
       " 0.44072413444519043,\n",
       " -0.06624676287174225,\n",
       " -0.35551950335502625,\n",
       " -0.2719663977622986,\n",
       " -0.03759041056036949,\n",
       " 0.4849175810813904,\n",
       " 0.4607577919960022,\n",
       " -0.633550226688385,\n",
       " -0.28805023431777954,\n",
       " 0.21789932250976562,\n",
       " 0.38232162594795227,\n",
       " -0.4069807231426239,\n",
       " 0.07960519939661026,\n",
       " 0.054545387625694275,\n",
       " 0.6147002577781677,\n",
       " -0.3776540160179138,\n",
       " -0.18038319051265717,\n",
       " -0.2316712737083435,\n",
       " -0.850265622138977,\n",
       " 0.19141152501106262,\n",
       " 0.21561923623085022,\n",
       " 0.057578105479478836,\n",
       " 0.0932120755314827,\n",
       " 0.3467790186405182,\n",
       " 0.04240547865629196,\n",
       " 0.01195273082703352,\n",
       " -0.13034847378730774,\n",
       " 0.21093203127384186,\n",
       " -0.2306562066078186,\n",
       " -0.45556363463401794,\n",
       " -0.11782945692539215,\n",
       " 0.6303227543830872,\n",
       " -0.13537363708019257,\n",
       " 0.013731973245739937,\n",
       " 0.24474318325519562,\n",
       " 0.3965526223182678,\n",
       " -0.2287142425775528,\n",
       " 0.23769511282444,\n",
       " 0.19581103324890137,\n",
       " -0.03512958809733391,\n",
       " -0.38724157214164734,\n",
       " -0.06367185711860657,\n",
       " -0.25063788890838623,\n",
       " 0.33500075340270996,\n",
       " 0.06774286180734634,\n",
       " 0.4702286720275879,\n",
       " -0.02326429821550846,\n",
       " 0.006659515667706728,\n",
       " -0.12194911390542984,\n",
       " -0.05648261308670044,\n",
       " 0.017357271164655685,\n",
       " -0.20856361091136932,\n",
       " -0.39768874645233154,\n",
       " -0.28227412700653076,\n",
       " 0.31395700573921204,\n",
       " 0.26073136925697327,\n",
       " -0.04575001820921898,\n",
       " 0.22020089626312256,\n",
       " 0.13939650356769562,\n",
       " 0.08534795790910721,\n",
       " -0.02633659355342388,\n",
       " 0.11662700027227402,\n",
       " 0.1766504943370819,\n",
       " -0.5145924091339111,\n",
       " -0.16168099641799927,\n",
       " 0.3515126705169678,\n",
       " 0.31436607241630554,\n",
       " 0.179096981883049,\n",
       " 0.4101618230342865,\n",
       " 0.1794089674949646,\n",
       " 0.630538821220398,\n",
       " -0.4086763560771942,\n",
       " -0.1483660638332367,\n",
       " 0.3154922127723694,\n",
       " -0.01196697261184454,\n",
       " -0.011775546707212925,\n",
       " 0.4971369206905365,\n",
       " -0.6993865966796875,\n",
       " -0.08286802470684052,\n",
       " -0.15817654132843018,\n",
       " -0.2527262270450592,\n",
       " 0.6061004996299744,\n",
       " 0.374050498008728,\n",
       " -0.20810961723327637,\n",
       " 0.030253684148192406,\n",
       " 0.09567942470312119,\n",
       " -0.5371994376182556,\n",
       " -0.5825846195220947,\n",
       " -0.4401755928993225,\n",
       " -0.20349088311195374,\n",
       " 0.06793893128633499,\n",
       " 0.09805402159690857,\n",
       " -1.0463802814483643,\n",
       " 0.07090634852647781,\n",
       " -0.4258915185928345,\n",
       " 0.20374850928783417,\n",
       " -0.13267368078231812,\n",
       " -0.6466412544250488,\n",
       " 0.2681710124015808,\n",
       " 0.7857125401496887,\n",
       " -0.25540691614151,\n",
       " -0.5712925791740417,\n",
       " 0.29319021105766296,\n",
       " -0.29338622093200684,\n",
       " -0.8268725275993347,\n",
       " 0.25620272755622864,\n",
       " -0.4729073941707611,\n",
       " 0.09161839634180069,\n",
       " -0.5234125256538391,\n",
       " -0.4173296093940735,\n",
       " 0.14259864389896393,\n",
       " 0.3194591999053955,\n",
       " 0.15802934765815735,\n",
       " 0.3450492322444916,\n",
       " -0.04197235777974129,\n",
       " 0.18202385306358337,\n",
       " 0.21053393185138702,\n",
       " -0.3719211518764496,\n",
       " -0.03188548609614372,\n",
       " 0.0038523550610989332,\n",
       " 0.15909965336322784,\n",
       " 0.3155677616596222,\n",
       " -0.0806339755654335,\n",
       " 0.15430954098701477,\n",
       " -0.25377586483955383,\n",
       " -0.287583589553833,\n",
       " 0.09746725857257843,\n",
       " -0.5662392377853394,\n",
       " -0.16874852776527405,\n",
       " 0.3929102122783661,\n",
       " -0.2216351181268692,\n",
       " 0.22437423467636108,\n",
       " 0.7242792844772339,\n",
       " 0.051782459020614624,\n",
       " -0.34943151473999023,\n",
       " 0.05943753942847252,\n",
       " 0.11891888082027435,\n",
       " 0.15835309028625488,\n",
       " 0.11911214888095856,\n",
       " 0.12558899819850922,\n",
       " 0.5061431527137756,\n",
       " -0.18067340552806854,\n",
       " -0.033557407557964325,\n",
       " 0.13261736929416656,\n",
       " -0.10395542532205582,\n",
       " -0.23017998039722443,\n",
       " -0.11035086214542389,\n",
       " -0.3333303928375244,\n",
       " 0.2072976529598236,\n",
       " -0.2530347406864166,\n",
       " 0.11270077526569366,\n",
       " 0.03449220582842827,\n",
       " 0.7576438188552856,\n",
       " -0.15746809542179108,\n",
       " -0.018596909940242767,\n",
       " -0.2477773129940033,\n",
       " -0.31749510765075684,\n",
       " 0.46356114745140076,\n",
       " -0.0016902392962947488,\n",
       " 0.2750128209590912,\n",
       " 0.10066144168376923,\n",
       " 0.036429598927497864,\n",
       " 0.19142867624759674,\n",
       " -0.2985922694206238,\n",
       " -0.9603590369224548,\n",
       " -0.0601462796330452,\n",
       " -0.1449628621339798,\n",
       " -0.5217819213867188,\n",
       " -0.17592039704322815,\n",
       " 0.43414855003356934,\n",
       " 0.12364444881677628,\n",
       " -0.20460623502731323,\n",
       " 0.2790416181087494,\n",
       " -0.5793620347976685,\n",
       " 0.3027469217777252,\n",
       " 0.2752580940723419,\n",
       " -0.0023011176381260157,\n",
       " 0.3696455955505371,\n",
       " 0.007620871998369694,\n",
       " -0.32655346393585205,\n",
       " 0.19803981482982635,\n",
       " -0.16558654606342316,\n",
       " -0.1515515148639679,\n",
       " 0.013914014212787151,\n",
       " 0.16957193613052368,\n",
       " 0.3536105751991272,\n",
       " -0.19944114983081818,\n",
       " -0.3011391758918762,\n",
       " 0.6191899180412292,\n",
       " -0.37651586532592773,\n",
       " 0.38297775387763977,\n",
       " -0.08179236948490143,\n",
       " 0.184726282954216,\n",
       " 0.5434118509292603,\n",
       " 0.11745807528495789,\n",
       " -0.6553367972373962,\n",
       " 0.3970312178134918,\n",
       " 0.7925774455070496,\n",
       " -0.2950524687767029,\n",
       " -0.14860957860946655,\n",
       " -0.08626206964254379,\n",
       " 0.15567567944526672,\n",
       " -0.34252044558525085,\n",
       " -0.3223314881324768,\n",
       " -0.07727882266044617,\n",
       " 0.3789283335208893]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.indexer.get_item_vector(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0960145965218544"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.indexer.get_distance(10, 301)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
